{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2255be7c-f6cb-451e-b5fd-1db1ea5a2e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments over GBSG\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import dataset_name\n",
    "print(f\"Experiments over {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbec2c38-6d19-421e-a270-d77a130c14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"../../datasets/train/{dataset_name}.csv\")\n",
    "test = pd.read_csv(f\"../../datasets/test/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb5031a-748e-46f3-9303-6b1ee6f9c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete instances with duration = 0.0\n",
    "idx = train[train[\"duration\"] == 0].index.values if (train[\"duration\"] == 0).any() else None\n",
    "if idx is not None:\n",
    "    train.drop(index=idx, inplace=True)\n",
    "idx = test[test[\"duration\"] == 0].index if (test[\"duration\"] == 0).any() else None\n",
    "if idx is not None:\n",
    "    test.drop(index=idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af100904-5dd8-4ccc-9428-d5e705a8442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SHAPE (2008, 9), TEST SHAPE (224, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAIN SHAPE {train.shape}, TEST SHAPE {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a70337be-5d68-41a4-ba5f-b2fe37108b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.drop([\"event\", \"duration\"], axis=1), train[[\"event\", \"duration\"]]\n",
    "X_test, y_test = test.drop([\"event\", \"duration\"], axis=1), test[[\"event\", \"duration\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1850561f-05eb-42fd-bb0b-d312cbd0619b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hyperparameters Tuning\n",
    "### The `grid_params` dict describe all the possible hyperparameter values i chose to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94aca34f-5e4a-40ae-a416-f35562ac9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "from lifelines.utils import concordance_index\n",
    "from pycox.evaluation import EvalSurv\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df67b425-285b-4a9f-88b6-a1644c5a34c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "CPU times: user 25min 1s, sys: 5min 27s, total: 30min 28s\n",
      "Wall time: 4min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"reg_coxph\"\n",
    "\n",
    "grid_params = {\n",
    "    \"l1_ratio\": np.arange(0.1, 1.1, 0.1),\n",
    "    \"tol\": [1e-09, 1e-07, 1e-05, 1e-03, 1e-01, 1],\n",
    "    \"max_iter\": [1000, 10000, 100000, 1000000],\n",
    "    \"verbose\": [False],\n",
    "    \"fit_baseline_model\": [True]\n",
    "}\n",
    "\n",
    "keys, values = zip(*grid_params.items())\n",
    "experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "for experiment in experiments:\n",
    "    Statistics = {'concordance_td':[], \n",
    "                  'ibs': [],\n",
    "                  'c_index': [],\n",
    "                  'avg_concordance_td':0.5, \n",
    "                  'avg_ibs': 0,\n",
    "                  'avg_c_index': 0.5,\n",
    "                  'std_concordance_td': 0,\n",
    "                  'std_ibs': 0,\n",
    "                  'std_c_index': 0                  \n",
    "                 }\n",
    "        \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for i, (train_index, val_index) in enumerate(cv.split(X)):\n",
    "        \n",
    "        # split to train and test \n",
    "        X_train, X_val = X.iloc[train_index].copy(), X.iloc[val_index].copy()\n",
    "        y_train, y_val = y.iloc[train_index].copy(), y.iloc[val_index].copy()\n",
    "        \n",
    "        # preprocess for y\n",
    "        lower, upper = np.min(y_train[\"duration\"]), np.max(y_train[\"duration\"])\n",
    "        idx = np.where((y_val[\"duration\"] > lower) & (y_val[\"duration\"] < upper))[0]\n",
    "        X_val = X_val.iloc[idx].copy()\n",
    "        y_val = y_val.iloc[idx].copy()\n",
    "\n",
    "        original_y_train = y_train.copy()\n",
    "        original_y_val = y_val.copy() \n",
    "        \n",
    "        y_train[\"event\"] = y_train[\"event\"].astype(bool)\n",
    "        y_train = y_train[[\"event\", \"duration\"]].to_records(index=False)\n",
    "        y_val[\"event\"] = y_val[\"event\"].astype(bool)\n",
    "        y_val = y_val[[\"event\", \"duration\"]].to_records(index=False)\n",
    "\n",
    "        # preprocess step\n",
    "        cols_standardize = ['x3', 'x4', 'x5', 'x6']\n",
    "        cols_leave = ['x0', 'x1', 'x2',]\n",
    "\n",
    "        standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "        leave = [(col, None) for col in cols_leave]\n",
    "\n",
    "        standard_scaler = DataFrameMapper(standardize + leave)\n",
    "        X_train = standard_scaler.fit_transform(X_train)\n",
    "        \n",
    "        # train the model\n",
    "        model = CoxnetSurvivalAnalysis(**experiment)        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # model evaluation\n",
    "        X_val = standard_scaler.fit_transform(X_val)\n",
    "        estimate = model.predict(X_val)\n",
    "        \n",
    "        ## pycox measures\n",
    "        original_y_train = original_y_train[\"duration\"].values, original_y_train[\"event\"].values                \n",
    "        original_y_val = original_y_val[\"duration\"].values, original_y_val[\"event\"].values        \n",
    "        \n",
    "        estimate_surv = model.predict_survival_function(X_val, return_array=True)\n",
    "        estimate_surv = pd.DataFrame(estimate_surv.T)\n",
    "        estimate_surv.index = model.event_times_\n",
    "\n",
    "        ev = EvalSurv(estimate_surv, original_y_val[0], original_y_val[1], censor_surv='km')\n",
    "\n",
    "        tmp_times = np.sort(original_y_train[0])\n",
    "        times = np.array([tmp_times[i] for i in range(0, len(tmp_times), 10)])\n",
    "\n",
    "        concordance_td = ev.concordance_td('antolini')\n",
    "\n",
    "        ibs = ev.integrated_brier_score(times)\n",
    "\n",
    "        ## lifelines measures\n",
    "        c_index = 1 - concordance_index(event_times = original_y_val[0], \n",
    "                          predicted_scores = estimate, \n",
    "                          event_observed = original_y_val[1])\n",
    "                        \n",
    "        # store statistics in Statistics dict\n",
    "        Statistics[\"c_index\"].append(c_index)\n",
    "        Statistics[\"ibs\"].append(ibs)\n",
    "        Statistics[\"concordance_td\"].append(concordance_td)\n",
    "        \n",
    "    # summarise cross validation scores\n",
    "    Statistics[\"avg_concordance_td\"] = np.mean(Statistics[\"concordance_td\"])\n",
    "    Statistics[\"avg_ibs\"] = np.mean(Statistics[\"ibs\"])\n",
    "    Statistics[\"avg_c_index\"] = np.mean(Statistics[\"c_index\"])    \n",
    "    Statistics[\"std_concordance_td\"] = np.std(Statistics[\"concordance_td\"])\n",
    "    Statistics[\"std_ibs\"] = np.std(Statistics[\"ibs\"])    \n",
    "    Statistics[\"std_c_index\"] = np.std(Statistics[\"c_index\"])\n",
    "    \n",
    "     # save the model for later\n",
    "    try:\n",
    "        os.mkdir(f\"statistics/{model_name}/models\")\n",
    "\n",
    "    except OSError as error: \n",
    "        file_name = f\"{model_name}_\"\n",
    "        for k,v in experiment.items():\n",
    "            file_name += f\"{str(k)}_{str(v)}_\"\n",
    "            \n",
    "        path_sc = os.path.join(f\"statistics/{model_name}/models\", f\"sc_{file_name}.pkl\")            \n",
    "        path_model = os.path.join(f\"statistics/{model_name}/models\", f\"model_{file_name}\")\n",
    "        \n",
    "        with open(path_sc, 'wb') as f:\n",
    "            pickle.dump(standard_scaler, f)\n",
    "            \n",
    "        with open(path_model, 'wb') as f:\n",
    "            pickle.dump(model, f)            \n",
    "            \n",
    "        # dump statistics to pickle    \n",
    "        file_name += \".pkl\"\n",
    "\n",
    "        path = os.path.join(f\"statistics/{model_name}\", file_name)\n",
    "\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(Statistics, f)\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a041424e-f812-4862-a6da-18c6a11ab9df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extract the best model for each one of the measurements\n",
    "`c_index` `concordance_td`, `integrated brier score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d44989f2-35dd-403e-a53c-66a4a7f99441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "best_statistics = {'concordance_td': -1, \n",
    "                  'ibs': 1,\n",
    "                   'c_index': -1\n",
    "                 }\n",
    "experiments_list = os.listdir(f\"statistics/{model_name}\")\n",
    "for experiment in experiments_list:\n",
    "    if not experiment.startswith(model_name):\n",
    "        continue\n",
    "        \n",
    "    path = os.path.join(f\"statistics/{model_name}\", experiment)\n",
    "    stats = pickle.load(open(path, \"rb\" ))\n",
    "    df = pd.DataFrame(stats)\n",
    "\n",
    "    concordance_td = df[\"avg_concordance_td\"][0]\n",
    "    std_concordance_td = df[\"std_concordance_td\"][0]\n",
    "    ibs = df[\"avg_ibs\"][0]\n",
    "    std_ibs = df[\"std_ibs\"][0]    \n",
    "    c_index = df[\"avg_c_index\"][0]\n",
    "    std_c_index = df[\"std_c_index\"][0]    \n",
    "    \n",
    "    if c_index > best_statistics[\"c_index\"]:\n",
    "        best_statistics[\"c_index\"] = c_index\n",
    "        best_statistics[\"c_index_std\"] = std_c_index\n",
    "        best_statistics[\"c_index_params\"] = experiment\n",
    "    \n",
    "    if concordance_td > best_statistics[\"concordance_td\"]:\n",
    "        best_statistics[\"concordance_td\"] = concordance_td\n",
    "        best_statistics[\"concordance_td_std\"] = std_concordance_td\n",
    "        best_statistics[\"concordance_td_params\"] = experiment\n",
    "        \n",
    "    if ibs < best_statistics[\"ibs\"]:\n",
    "        best_statistics[\"ibs\"] = ibs\n",
    "        best_statistics[\"ibs_std\"] = std_ibs\n",
    "        best_statistics[\"ibs_params\"] = experiment\n",
    "\n",
    "\n",
    "\n",
    "path = os.path.join(f\"statistics/{model_name}\", \"best_model.pkl\")\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(best_statistics, f)    \n",
    "    \n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bdb707-a761-4bc3-95f0-d4e4553f5a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sa-proj-ker",
   "language": "python",
   "name": "sa-proj-ker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
