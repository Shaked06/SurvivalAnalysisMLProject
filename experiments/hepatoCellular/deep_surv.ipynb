{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2255be7c-f6cb-451e-b5fd-1db1ea5a2e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments over hepatoCellular\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import dataset_name\n",
    "print(f\"Experiments over {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbec2c38-6d19-421e-a270-d77a130c14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"../../datasets/train/{dataset_name}.csv\")\n",
    "test = pd.read_csv(f\"../../datasets/test/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2903a1-16bb-4837-81d6-af2357444ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete instances with duration = 0.0\n",
    "idx = train[train[\"duration\"] == 0].index.values if (train[\"duration\"] == 0).any() else None\n",
    "if idx is not None:\n",
    "    train.drop(index=idx, inplace=True)\n",
    "idx = test[test[\"duration\"] == 0].index if (test[\"duration\"] == 0).any() else None\n",
    "if idx is not None:\n",
    "    test.drop(index=idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af100904-5dd8-4ccc-9428-d5e705a8442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SHAPE (204, 45), TEST SHAPE (23, 45)\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAIN SHAPE {train.shape}, TEST SHAPE {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a70337be-5d68-41a4-ba5f-b2fe37108b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.drop([\"event\", \"duration\"], axis=1), train[[\"event\", \"duration\"]]\n",
    "X_test, y_test = test.drop([\"event\", \"duration\"], axis=1), test[[\"event\", \"duration\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fac4c66-5047-43b9-8d3c-5b87f70c225a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HBsAg</th>\n",
       "      <th>Cirrhosis</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>AFP</th>\n",
       "      <th>Tumorsize</th>\n",
       "      <th>Tumordifferentiation</th>\n",
       "      <th>Vascularinvasion</th>\n",
       "      <th>...</th>\n",
       "      <th>CD15NR</th>\n",
       "      <th>CD68NR</th>\n",
       "      <th>CD4TR</th>\n",
       "      <th>CD8TR</th>\n",
       "      <th>CD20TR</th>\n",
       "      <th>CD57TR</th>\n",
       "      <th>CD15TR</th>\n",
       "      <th>CD68TR</th>\n",
       "      <th>Ki67</th>\n",
       "      <th>CD34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050232</td>\n",
       "      <td>0.444623</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.175472</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.483644</td>\n",
       "      <td>0.298016</td>\n",
       "      <td>141.066438</td>\n",
       "      <td>26008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105249</td>\n",
       "      <td>0.529443</td>\n",
       "      <td>0.096607</td>\n",
       "      <td>0.138420</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.033657</td>\n",
       "      <td>0.080774</td>\n",
       "      <td>0.571242</td>\n",
       "      <td>303.015295</td>\n",
       "      <td>46160.267327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  HBsAg  Cirrhosis  ALT  AST  AFP  Tumorsize  \\\n",
       "0   59       1      1          0    1    1    1          2   \n",
       "1   37       1      1          1    2    2    1          2   \n",
       "\n",
       "   Tumordifferentiation  Vascularinvasion  ...    CD15NR    CD68NR     CD4TR  \\\n",
       "0                     2                 0  ...  0.050232  0.444623  0.014289   \n",
       "1                     1                 0  ...  0.105249  0.529443  0.096607   \n",
       "\n",
       "      CD8TR    CD20TR    CD57TR    CD15TR    CD68TR        Ki67          CD34  \n",
       "0  0.175472  0.014289  0.014289  0.483644  0.298016  141.066438  26008.000000  \n",
       "1  0.138420  0.079300  0.033657  0.080774  0.571242  303.015295  46160.267327  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1850561f-05eb-42fd-bb0b-d312cbd0619b",
   "metadata": {},
   "source": [
    "# Hyperparameters Tuning\n",
    "### The `grid_params` dict describe all the possible hyperparameter values i chose to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94aca34f-5e4a-40ae-a416-f35562ac9a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycox.models import CoxPH\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import KFold\n",
    "from pycox.evaluation import EvalSurv\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "from torch.nn.modules.activation import ReLU, SELU\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "np.random.seed(42)\n",
    "_ = torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df67b425-285b-4a9f-88b6-a1644c5a34c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "CPU times: user 10min 25s, sys: 13min 38s, total: 24min 4s\n",
      "Wall time: 9min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"deep_surv\"\n",
    "\n",
    "grid_params = {\n",
    "    # net params\n",
    "    \"dropout\": [0.2, 0.1],\n",
    "    \"num_nodes\": [[100], [32, 32], [28,28,100,28,28], [32,128,128,100,100], [16,32,64,64]],\n",
    "    \"activation\": [ReLU, SELU],\n",
    "    # fit params\n",
    "    \"batch_size\": [256, 512],\n",
    "    \"epochs\": [256, 512],\n",
    "    # optimizer params\n",
    "    \"lr\": [1e-2, 1e-3],\n",
    "    \"weight_decay\": [1e-2, 1e-3]\n",
    "    \n",
    "}\n",
    "\n",
    "keys, values = zip(*grid_params.items())\n",
    "experiments = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "for experiment in experiments:\n",
    "    Statistics = {'concordance_td':[], \n",
    "                  'ibs': [],\n",
    "                  'c_index': [],\n",
    "                  'avg_concordance_td':0.5, \n",
    "                  'avg_ibs': 0,\n",
    "                  'avg_c_index': 0.5,\n",
    "                  'std_concordance_td': 0,\n",
    "                  'std_ibs': 0,\n",
    "                  'std_c_index': 0                  \n",
    "                 }\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for i, (train_index, val_index) in enumerate(cv.split(X)):\n",
    "\n",
    "        # split to train and test \n",
    "        X_train, X_val = X.iloc[train_index].copy(), X.iloc[val_index].copy()\n",
    "        y_train, y_val = y.iloc[train_index].copy(), y.iloc[val_index].copy()\n",
    "\n",
    "        # preprocess for y\n",
    "        lower, upper = np.min(y_train[\"duration\"]), np.max(y_train[\"duration\"])\n",
    "        idx = np.where((y_val[\"duration\"] > lower) & (y_val[\"duration\"] < upper))[0]\n",
    "        X_val = X_val.iloc[idx].copy()\n",
    "        y_val = y_val.iloc[idx].copy()\n",
    "        \n",
    "        original_y_train = y_train.copy()\n",
    "        original_y_val = y_val.copy()\n",
    "        \n",
    "        # preprocess step\n",
    "        cols_standardize = ['CXCL17T', 'CXCL17P', 'CXCL17N', 'CD4T',\n",
    "                               'CD4N', 'CD8T', 'CD8N', 'CD20T', 'CD20N', 'CD57T', 'CD57N', 'CD15T',\n",
    "                               'CD15N', 'CD68T', 'CD68N', 'CD4NR', 'CD8NR', 'CD20NR', 'CD57NR',\n",
    "                               'CD15NR', 'CD68NR', 'CD4TR', 'CD8TR', 'CD20TR', 'CD57TR', 'CD15TR',\n",
    "                               'CD68TR', 'Ki67', 'CD34']\n",
    "        cols_leave = [\"Gender\", \"HBsAg\", \"Cirrhosis\", \"ALT\", \"AST\", \"AFP\", \n",
    "                                          \"Tumorsize\", \"Tumordifferentiation\", \"Vascularinvasion\", \n",
    "                                          \"Tumormultiplicity\", \"Capsulation\", \"TNM\", \"BCLC\"]\n",
    "        \n",
    "        standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "        leave = [(col, None) for col in cols_leave]\n",
    "\n",
    "        standard_scaler = DataFrameMapper(standardize + leave)\n",
    "        X_train = standard_scaler.fit_transform(X_train).astype('float32')\n",
    "        y_train = y_train[\"duration\"].values, y_train[\"event\"].values\n",
    "\n",
    "        X_val = standard_scaler.transform(X_val).astype('float32')\n",
    "        y_val = y_val[\"duration\"].values, y_val[\"event\"].values\n",
    "        val = X_val, y_val\n",
    "        \n",
    "        # build the network\n",
    "        in_features = X_train.shape[1]\n",
    "        num_nodes = experiment[\"num_nodes\"]\n",
    "        dropout = experiment[\"dropout\"]\n",
    "        activation = experiment[\"activation\"]\n",
    "        out_features = 1\n",
    "        batch_norm = True\n",
    "        output_bias = False\n",
    "        \n",
    "        net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm,\n",
    "                              dropout, activation, output_bias=output_bias)\n",
    "\n",
    "        optimizer = tt.optim.Adam(lr=experiment[\"lr\"],\n",
    "                                  weight_decay = experiment[\"weight_decay\"])\n",
    "        model = CoxPH(net, optimizer)\n",
    "\n",
    "        # fit params\n",
    "        batch_size = experiment[\"batch_size\"]\n",
    "        epochs = experiment[\"epochs\"]\n",
    "        callbacks = [tt.callbacks.EarlyStopping()]\n",
    "        verbose = False\n",
    "\n",
    "        # train the model\n",
    "        log = model.fit(X_train, y_train, batch_size, epochs, callbacks, verbose,\n",
    "                val_data=val, val_batch_size=batch_size)\n",
    "\n",
    "\n",
    "        # model evaluation\n",
    "\n",
    "        ## pycox measures\n",
    "        _ = model.compute_baseline_hazards(X_train, y_train)\n",
    "        estimate_surv = model.predict_surv_df(X_val)\n",
    "        ev = EvalSurv(estimate_surv, y_val[0], y_val[1], censor_surv='km')\n",
    "\n",
    "        tmp_times = np.sort(y_train[0])\n",
    "        times = np.array([tmp_times[i] for i in range(0, len(tmp_times), 10)])\n",
    "\n",
    "        concordance_td = ev.concordance_td('antolini')\n",
    "        ibs = ev.integrated_brier_score(times)\n",
    "\n",
    "        ## lifelines measures\n",
    "        estimate = np.mean(1-estimate_surv, axis=0)\n",
    "        c_index = 1 - concordance_index(event_times=original_y_val[\"duration\"], \n",
    "                          predicted_scores= estimate, \n",
    "                          event_observed=original_y_val[\"event\"])\n",
    "\n",
    "        # store statistics in Statistics dict\n",
    "        Statistics[\"c_index\"].append(c_index)\n",
    "        Statistics[\"ibs\"].append(ibs)\n",
    "        Statistics[\"concordance_td\"].append(concordance_td)\n",
    "\n",
    "    # summarise cross validation scores\n",
    "    Statistics[\"avg_concordance_td\"] = np.mean(Statistics[\"concordance_td\"])\n",
    "    Statistics[\"avg_ibs\"] = np.mean(Statistics[\"ibs\"])\n",
    "    Statistics[\"avg_c_index\"] = np.mean(Statistics[\"c_index\"])    \n",
    "    Statistics[\"std_concordance_td\"] = np.std(Statistics[\"concordance_td\"])\n",
    "    Statistics[\"std_ibs\"] = np.std(Statistics[\"ibs\"])    \n",
    "    Statistics[\"std_c_index\"] = np.std(Statistics[\"c_index\"])\n",
    "\n",
    "    # save the model for later\n",
    "    try:\n",
    "        os.mkdir(f\"statistics/{model_name}/models\")\n",
    "\n",
    "    except OSError as error: \n",
    "        \n",
    "        file_name = f\"{model_name}_\"\n",
    "        for k,v in experiment.items():\n",
    "            file_name += f\"{str(k)}_{str(v)}_\"\n",
    "        \n",
    "        # dump model to files\n",
    "        path_sc = os.path.join(f\"statistics/{model_name}/models\", f\"sc_{file_name}.pkl\")            \n",
    "        path_net = os.path.join(f\"statistics/{model_name}/models\", f\"net_{file_name}\")\n",
    "        path_weights = os.path.join(f\"statistics/{model_name}/models\", f\"weights_{file_name}\")\n",
    "        \n",
    "        with open(path_sc, 'wb') as f:\n",
    "            pickle.dump(standard_scaler, f)\n",
    "            \n",
    "        model.save_net(path_net)\n",
    "        model.save_model_weights(path_weights)\n",
    "    \n",
    "        # dump statistics to pickle    \n",
    "        file_name += \".pkl\"\n",
    "        path = os.path.join(f\"statistics/{model_name}\", file_name)\n",
    "\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(Statistics, f)\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a041424e-f812-4862-a6da-18c6a11ab9df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extract the best model for each one of the measurements\n",
    "`c_index` `concordance_td`, `integrated brier score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d44989f2-35dd-403e-a53c-66a4a7f99441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "best_statistics = {'concordance_td': -1, \n",
    "                  'ibs': 1,\n",
    "                   'c_index': -1\n",
    "                 }\n",
    "experiments_list = os.listdir(f\"statistics/{model_name}\")\n",
    "for experiment in experiments_list:\n",
    "    if not experiment.startswith(model_name):\n",
    "        continue\n",
    "        \n",
    "    path = os.path.join(f\"statistics/{model_name}\", experiment)\n",
    "    stats = pickle.load(open(path, \"rb\" ))\n",
    "    df = pd.DataFrame(stats)\n",
    "\n",
    "    concordance_td = df[\"avg_concordance_td\"][0]\n",
    "    std_concordance_td = df[\"std_concordance_td\"][0]\n",
    "    ibs = df[\"avg_ibs\"][0]\n",
    "    std_ibs = df[\"std_ibs\"][0]    \n",
    "    c_index = df[\"avg_c_index\"][0]\n",
    "    std_c_index = df[\"std_c_index\"][0]    \n",
    "    \n",
    "    if c_index > best_statistics[\"c_index\"]:\n",
    "        best_statistics[\"c_index\"] = c_index\n",
    "        best_statistics[\"c_index_std\"] = std_c_index\n",
    "        best_statistics[\"c_index_params\"] = experiment\n",
    "    \n",
    "    if concordance_td > best_statistics[\"concordance_td\"]:\n",
    "        best_statistics[\"concordance_td\"] = concordance_td\n",
    "        best_statistics[\"concordance_td_std\"] = std_concordance_td\n",
    "        best_statistics[\"concordance_td_params\"] = experiment\n",
    "        \n",
    "    if ibs < best_statistics[\"ibs\"]:\n",
    "        best_statistics[\"ibs\"] = ibs\n",
    "        best_statistics[\"ibs_std\"] = std_ibs\n",
    "        best_statistics[\"ibs_params\"] = experiment\n",
    "\n",
    "\n",
    "\n",
    "path = os.path.join(f\"statistics/{model_name}\", \"best_model.pkl\")\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(best_statistics, f)    \n",
    "    \n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bdb707-a761-4bc3-95f0-d4e4553f5a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sa-proj-ker",
   "language": "python",
   "name": "sa-proj-ker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
